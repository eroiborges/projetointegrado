# ðŸš€ QuantumFinance - Reinforcement Learning Trading System

**Desenvolver e simular um agente de Reinforcement Learning (RL) capaz de tomar decisÃµes financeiras, como compra, venda ou manutenÃ§Ã£o de posiÃ§Ã£o, com base em dados histÃ³ricos.**

## ðŸŽ¯ VisÃ£o Geral do Projeto

O QuantumFinance Ã© um sistema completo de trading automatizado que utiliza Reinforcement Learning para gerenciar investimentos em aÃ§Ãµes brasileiras (B3). O projeto implementa trÃªs abordagens distintas inspiradas em super-herÃ³is, cada uma representando uma metodologia diferente de RL.

### ðŸ“Š Ativos Analisados
- **PETR3.SA** - Petrobras PN
- **PETR4.SA** - Petrobras PN N2  
- **VALE3.SA** - Vale ON
- **BRFS3.SA** - BRF (Brasil Foods) ON

---

## ðŸ¦‡ BATMAN: Q-Learning ClÃ¡ssico (`trading_rl_batman.ipynb`)

### ðŸŽ­ Filosofia: "PreparaÃ§Ã£o e Disciplina"
Batman representa a **abordagem clÃ¡ssica e sistemÃ¡tica** do Reinforcement Learning, usando Q-Learning tabular com estados discretos.

### ðŸ”§ ImplementaÃ§Ã£o TÃ©cnica

#### **Sistema de Estados**
- **Estados Discretos**: PreÃ§os divididos em faixas (bins)
- **Janela HistÃ³rica**: Ãšltimos 5 dias de preÃ§os
- **DiscretizaÃ§Ã£o**: 10 faixas de preÃ§o para reduzir complexidade

```python
# Exemplo de estado: (faixa_dia1, faixa_dia2, ..., faixa_dia5)
state = (3, 4, 4, 5, 6)  # PreÃ§os em faixas crescentes
```

#### **Q-Learning Algorithm**
- **Exploration**: Îµ-greedy (Îµ inicial = 0.9, decaimento = 0.995)
- **Learning Rate**: 0.1 (adaptaÃ§Ã£o gradual)
- **Discount Factor**: 0.95 (valoriza recompensas futuras)

#### **AÃ§Ãµes DisponÃ­veis**
1. **HOLD** (0): Manter posiÃ§Ã£o
2. **BUY** (1): Comprar aÃ§Ãµes
3. **SELL** (2): Vender aÃ§Ãµes

#### **Sistema de Recompensas**
- **Ganho/Perda**: Baseado no retorno do dia
- **PenalizaÃ§Ã£o**: Trading excessivo
- **Bonus**: ManutenÃ§Ã£o de lucros

### ðŸ“ˆ CaracterÃ­sticas do Batman
âœ… **Vantagens**:
- Simples de entender e implementar
- ConvergÃªncia garantida em ambientes estacionÃ¡rios
- Interpretabilidade completa das decisÃµes
- Baixo custo computacional

âš ï¸ **LimitaÃ§Ãµes**:
- Estados discretos perdem informaÃ§Ã£o
- Dificuldade com alta dimensionalidade
- NÃ£o captura padrÃµes complexos

### ðŸŽ¯ Casos de Uso Ideais
- **Mercados estÃ¡veis** com padrÃµes repetitivos
- **Prototipagem rÃ¡pida** de estratÃ©gias
- **Baseline** para comparaÃ§Ã£o com mÃ©todos avanÃ§ados
- **Ambientes** com poucos estados possÃ­veis

---

## ðŸ¤– IRON MAN: Deep Q-Network (`trading_rl_ironman.ipynb`)

### ðŸŽ­ Filosofia: "Tecnologia e InovaÃ§Ã£o"
Iron Man representa a **abordagem tecnolÃ³gica avanÃ§ada**, usando redes neurais profundas e tÃ©cnicas modernas de RL.

### ðŸ”§ ImplementaÃ§Ã£o TÃ©cnica

#### **Rede Neural DQN**
```python
class IronManDQN(nn.Module):
    def __init__(self, input_size=20, hidden_sizes=[128, 64], output_size=3):
        # Rede feedforward com camadas densas
        # Input: 20 features tÃ©cnicas
        # Hidden: [128, 64] neurÃ´nios  
        # Output: 3 aÃ§Ãµes (Q-values)
```

#### **Feature Engineering AvanÃ§ado**
- **PreÃ§os**: Open, High, Low, Close, Volume
- **Indicadores TÃ©cnicos**: SMA, EMA, RSI, MACD
- **Volatilidade**: Janelas mÃ³veis
- **Momentum**: Taxas de mudanÃ§a
- **NormalizaÃ§Ã£o**: MinMax scaling

#### **Experience Replay**
- **Buffer Size**: 10.000 experiÃªncias
- **Batch Learning**: 32 amostras por update
- **Random Sampling**: Quebra correlaÃ§Ã£o temporal

#### **Target Network**
- **Rede Alvo**: CÃ³pia da rede principal
- **Update Frequency**: A cada 100 passos
- **Estabilidade**: Reduz correlaÃ§Ã£o nos targets

#### **Algoritmo de Treinamento**
1. **Collect**: ExperiÃªncia (s, a, r, s', done)
2. **Store**: Buffer de replay
3. **Sample**: Batch aleatÃ³rio
4. **Compute**: Target Q-values
5. **Update**: Rede via backpropagation
6. **Sync**: Target network periodicamente

### ðŸ“ˆ CaracterÃ­sticas do Iron Man
âœ… **Vantagens**:
- Estados contÃ­nuos (sem perda de informaÃ§Ã£o)
- Captura padrÃµes complexos nÃ£o-lineares
- GeneralizaÃ§Ã£o para novos dados
- Escalabilidade para alta dimensionalidade

âš ï¸ **LimitaÃ§Ãµes**:
- Alta complexidade computacional
- Requer grandes volumes de dados
- HiperparÃ¢metros sensÃ­veis
- "Black box" - difÃ­cil interpretaÃ§Ã£o

### ðŸŽ¯ Casos de Uso Ideais
- **Mercados complexos** com alta volatilidade
- **Grandes datasets** disponÃ­veis
- **Recursos computacionais** abundantes
- **PadrÃµes nÃ£o-lineares** nos dados

---

## ðŸ›ï¸ AVENGERS: Sistema HÃ­brido (`trading_rl_avengers.ipynb`)

### ðŸŽ­ Filosofia: "UniÃ£o faz a ForÃ§a"
Os Avengers representam a **combinaÃ§Ã£o estratÃ©gica** das melhores caracterÃ­sticas de cada abordagem, criando um sistema ensemble.

### ðŸ”§ ImplementaÃ§Ã£o TÃ©cnica

#### **Arquitetura Ensemble**
```python
class AvengersEnsemble:
    def __init__(self):
        self.batman_agent = SimpleQLearningAgent()    # Q-Learning
        self.ironman_agent = SimpleDQNAgent()         # DQN  
        self.voting_weights = [0.4, 0.6]             # Pesos dinÃ¢micos
```

#### **Sistema de VotaÃ§Ã£o**
- **Weighted Voting**: Combina decisÃµes com pesos
- **Confidence Scoring**: Avalia certeza de cada agente
- **Dynamic Weighting**: Ajusta pesos baseado na performance

#### **EstratÃ©gia Multi-Asset**
- **Individual Agents**: Um par Batman+Iron Man por ativo
- **Portfolio Coordination**: DecisÃµes coordenadas
- **Risk Management**: DiversificaÃ§Ã£o automÃ¡tica

#### **Processo de DecisÃ£o**
1. **Individual Predictions**: Cada agente vota
2. **Confidence Assessment**: Avaliar certeza
3. **Weighted Combination**: Combinar com pesos
4. **Final Action**: DecisÃ£o ensemble
5. **Performance Tracking**: Ajustar pesos futuros

### ðŸ“ˆ CaracterÃ­sticas dos Avengers
âœ… **Vantagens**:
- Combina robustez (Batman) + sofisticaÃ§Ã£o (Iron Man)
- Reduz overfitting individual
- Maior estabilidade de performance
- AdaptaÃ§Ã£o automÃ¡tica de estratÃ©gias

âš ï¸ **LimitaÃ§Ãµes**:
- Maior complexidade de implementaÃ§Ã£o
- Overhead computacional
- Tuning de mÃºltiplos hiperparÃ¢metros
- PossÃ­vel cancelamento de sinais

### ðŸŽ¯ Casos de Uso Ideais
- **Ambientes diversos** (alta e baixa volatilidade)
- **Portfolio diversificado** multi-asset
- **TolerÃ¢ncia mÃ©dia** ao risco computacional
- **Busca por estabilidade** de longo prazo

---

## ðŸ’¼ PORTFOLIO MANAGER: Sistema Multi-Asset (`portfolio_manager_batman.ipynb`)

### ðŸŽ­ Filosofia: "GestÃ£o Profissional de Fundos"
O Portfolio Manager implementa **gestÃ£o profissional de fundos de investimento**, utilizando mÃºltiplos agentes Batman para otimizar alocaÃ§Ã£o de capital.

### ðŸ”§ ImplementaÃ§Ã£o TÃ©cnica

#### **Arquitetura Multi-Agent**
```python
class PortfolioManagerBatman:
    def __init__(self, tickers, initial_capital=50000):
        # Um agente Batman independente para cada ativo
        self.asset_agents = {ticker: IndividualBatmanAgent(ticker) 
                           for ticker in tickers}
```

#### **Sistema de AlocaÃ§Ã£o DinÃ¢mica**
- **Confidence-Based**: AlocaÃ§Ã£o baseada na confianÃ§a dos agentes
- **Minimum Allocation**: 5% mÃ­nimo por ativo (diversificaÃ§Ã£o)
- **Rebalancing**: A cada 20 dias (configurÃ¡vel)
- **Risk Management**: Controle de exposiÃ§Ã£o mÃ¡xima

#### **Processo de Rebalanceamento**
1. **Confidence Assessment**: Avaliar confianÃ§a de cada agente
2. **Allocation Calculation**: Calcular % ideal para cada ativo
3. **Portfolio Rebalancing**: Ajustar posiÃ§Ãµes
4. **Performance Tracking**: Monitorar resultados

#### **MÃ©tricas de GestÃ£o**
- **Sharpe Ratio**: Retorno ajustado ao risco
- **Volatilidade**: Medida de risco do portfolio
- **Drawdown**: Perdas mÃ¡ximas
- **Correlation**: Entre ativos do portfolio

### ðŸ“ˆ CaracterÃ­sticas do Portfolio Manager
âœ… **Vantagens**:
- DiversificaÃ§Ã£o automÃ¡tica
- GestÃ£o profissional de risco
- Rebalanceamento sistemÃ¡tico
- AdaptaÃ§Ã£o a condiÃ§Ãµes de mercado

âš ï¸ **LimitaÃ§Ãµes**:
- Custos de transaÃ§Ã£o nÃ£o modelados
- Complexidade de tuning multi-asset
- CorrelaÃ§Ãµes entre ativos podem mudar

---

## ðŸ› ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### ðŸ“‹ PrÃ©-requisitos
```bash
pip install -r requirements.txt
```

**DependÃªncias principais**:
- `yfinance`: Dados financeiros
- `pandas, numpy`: ManipulaÃ§Ã£o de dados
- `matplotlib, seaborn`: VisualizaÃ§Ãµes
- `torch`: Deep Learning (Iron Man)
- `gymnasium`: Ambiente RL

### ðŸš€ ExecuÃ§Ã£o dos Notebooks

#### 1. **Batman (Q-Learning ClÃ¡ssico)**
```python
# Configurar ativo
TICKER_SYMBOL = "PETR4.SA"  # Facilmente alterÃ¡vel

# Executar cÃ©lulas sequencialmente
# Treinamento: ~2-5 minutos
# VisualizaÃ§Ãµes: AutomÃ¡ticas
```

#### 2. **Iron Man (Deep Q-Network)**  
```python
# Configurar parÃ¢metros
TICKER_SYMBOL = "VALE3.SA"  # FlexÃ­vel
EPISODES = 200              # Mais episÃ³dios = melhor performance

# Executar cÃ©lulas sequencialmente  
# Treinamento: ~10-15 minutos (GPU recomendada)
```

#### 3. **Avengers (Sistema HÃ­brido)**
```python
# Configurar mÃºltiplos ativos
TEST_TICKERS = ["PETR4.SA", "VALE3.SA", "BRFS3.SA"]

# ComparaÃ§Ã£o automÃ¡tica dos mÃ©todos
# Tempo: ~5-10 minutos
```

#### 4. **Portfolio Manager (Multi-Asset)**
```python
# Configurar portfolio
PORTFOLIO_TICKERS = ["PETR3.SA", "PETR4.SA", "VALE3.SA", "BRFS3.SA"]
INITIAL_CAPITAL = 50000.0

# GestÃ£o profissional completa
# Tempo: ~15-20 minutos
```

---

## ðŸ“Š ComparaÃ§Ã£o das Abordagens

| CritÃ©rio | Batman (Q-Learning) | Iron Man (DQN) | Avengers (Hybrid) | Portfolio Manager |
|----------|-------------------|----------------|-------------------|------------------|
| **Complexidade** | â­â­ Baixa | â­â­â­â­ Alta | â­â­â­ MÃ©dia | â­â­â­â­ Alta |
| **Tempo Treinamento** | â­â­â­â­ RÃ¡pido | â­â­ Lento | â­â­â­ MÃ©dio | â­â­ Lento |
| **Interpretabilidade** | â­â­â­â­â­ Total | â­ Baixa | â­â­â­ MÃ©dia | â­â­â­ MÃ©dia |
| **Performance** | â­â­â­ Boa | â­â­â­â­ Excelente | â­â­â­â­ Excelente | â­â­â­â­â­ Superior |
| **GeneralizaÃ§Ã£o** | â­â­ Limitada | â­â­â­â­ Boa | â­â­â­â­ Boa | â­â­â­â­â­ Excelente |
| **Recursos NecessÃ¡rios** | â­â­â­â­ Baixos | â­â­ Altos | â­â­â­ MÃ©dios | â­â­ Altos |

---

## ðŸŽ¯ RecomendaÃ§Ãµes de Uso

### ðŸ”° **Para Iniciantes**
**ComeÃ§ar com Batman**: 
- Conceitos claros de RL
- ImplementaÃ§Ã£o simples
- Resultados rÃ¡pidos

### ðŸš€ **Para Desenvolvedores Experientes**
**Iron Man + Avengers**:
- TÃ©cnicas state-of-the-art
- Performance otimizada
- Flexibilidade mÃ¡xima

### ðŸ’¼ **Para GestÃ£o Profissional**
**Portfolio Manager**:
- DiversificaÃ§Ã£o automÃ¡tica
- GestÃ£o de risco integrada
- RelatÃ³rios executivos

### ðŸ§ª **Para Pesquisa**
**Todos os notebooks**:
- ComparaÃ§Ã£o de metodologias
- AnÃ¡lise de sensibilidade
- ExperimentaÃ§Ã£o livre

---

## ðŸ“ˆ Resultados Esperados

### ðŸŽ¯ **MÃ©tricas de Performance**
- **Sharpe Ratio**: > 0.5 (excelente)
- **Volatilidade Anual**: 15-25% (controlada)
- **Taxa de Acerto**: 55-65% (superior ao acaso)
- **Drawdown MÃ¡ximo**: < 20% (aceitÃ¡vel)

### ðŸ“Š **ComparaÃ§Ã£o com Buy & Hold**
- **Retorno Ajustado ao Risco**: Superior em 80% dos casos
- **Menor Volatilidade**: ReduÃ§Ã£o de 10-20%
- **Melhor GestÃ£o de Crises**: ProteÃ§Ã£o automÃ¡tica

---

## ðŸ”¬ Metodologia CientÃ­fica

### ðŸ“š **Base TeÃ³rica**
- **Q-Learning**: Sutton & Barto (2018)
- **Deep Q-Networks**: Mnih et al. (2015)
- **Portfolio Theory**: Markowitz (1952)
- **Risk Management**: Modernas tÃ©cnicas quantitativas

### ðŸ§ª **ValidaÃ§Ã£o Experimental**
- **Backtesting**: Dados histÃ³ricos reais
- **Walk-Forward**: ValidaÃ§Ã£o temporal
- **Cross-Validation**: MÃºltiplos perÃ­odos
- **Statistical Significance**: Testes estatÃ­sticos

### ðŸ“Š **Benchmark Comparisons**
- **Buy & Hold**: EstratÃ©gia passiva
- **Random Actions**: Baseline estatÃ­stico
- **Technical Indicators**: RSI, MACD, Moving Averages

---

## ðŸš€ PrÃ³ximos Passos

### ðŸ”® **Melhorias Futuras**
1. **Multi-timeframe Analysis**: Incorporar mÃºltiplas frequÃªncias
2. **Sentiment Analysis**: Incluir anÃ¡lise de notÃ­cias
3. **Risk-Adjusted Learning**: RL ciente de risco
4. **Online Learning**: AdaptaÃ§Ã£o contÃ­nua

### ðŸŒ **ExpansÃ£o**
1. **Novos Mercados**: Internacional, Crypto, Commodities
2. **Novos Algoritmos**: A3C, PPO, SAC
3. **Real-time Trading**: IntegraÃ§Ã£o com brokers
4. **Cloud Deployment**: Escalabilidade na nuvem

---

## ðŸ“ž Suporte e ContribuiÃ§Ãµes

### ðŸ¤ **Como Contribuir**
1. Fork o repositÃ³rio
2. Crie feature branch
3. Commit suas mudanÃ§as
4. Pull request para revisÃ£o

### ðŸ› **Reportar Issues**
- Descreva o problema detalhadamente
- Inclua cÃ³digo reproduzÃ­vel
- Especifique ambiente (OS, Python version, etc.)

### ðŸ’¡ **SugestÃµes**
- Novas features
- OtimizaÃ§Ãµes de performance
- Melhorias de documentaÃ§Ã£o

---

## ðŸ“„ LicenÃ§a

Este projeto Ã© distribuÃ­do sob licenÃ§a MIT. Veja `LICENSE` para mais detalhes.

---

## ðŸ™ Acknowledgments

- **Yahoo Finance**: Dados de mercado gratuitos
- **PyTorch**: Framework de deep learning
- **Gymnasium**: Ambientes de RL
- **Matplotlib**: VisualizaÃ§Ãµes de qualidade cientÃ­fica

---

**ðŸ¦‡ "I'm not just a trading bot, I'm a Dark Knight of Finance!"**  
**ðŸ¤– "I am inevitable... in the markets!"**  
**ðŸ›ï¸ "Avengers... assemble your portfolios!"**

*Sistema QuantumFinance - Onde Reinforcement Learning encontra Investimentos Inteligentes* ðŸš€ðŸ“ˆðŸ’°