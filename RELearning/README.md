# üöÄ QuantumFinance - Reinforcement Learning Trading System

**Desenvolver e simular um agente de Reinforcement Learning (RL) capaz de tomar decis√µes financeiras, como compra, venda ou manuten√ß√£o de posi√ß√£o, com base em dados hist√≥ricos.**

## üéØ Vis√£o Geral do Projeto

O QuantumFinance √© um sistema completo de trading automatizado que utiliza Reinforcement Learning para gerenciar investimentos em a√ß√µes brasileiras (B3). O projeto implementa tr√™s abordagens distintas inspiradas em super-her√≥is, cada uma representando uma metodologia diferente de RL.

### üìä Ativos Analisados
- **PETR3.SA** - Petrobras PN
- **PETR4.SA** - Petrobras PN N2  
- **VALE3.SA** - Vale ON
- **BRFS3.SA** - BRF (Brasil Foods) ON

---

## ü¶á BATMAN: Q-Learning Cl√°ssico (`trading_rl_batman.ipynb`)

### üé≠ Filosofia: "Prepara√ß√£o e Disciplina"
Batman representa a **abordagem cl√°ssica e sistem√°tica** do Reinforcement Learning, usando Q-Learning tabular com estados discretos.

### üîß Implementa√ß√£o T√©cnica

#### **Sistema de Estados**
- **Estados Discretos**: Pre√ßos divididos em faixas (bins)
- **Janela Hist√≥rica**: √öltimos 5 dias de pre√ßos
- **Discretiza√ß√£o**: 10 faixas de pre√ßo para reduzir complexidade

```python
# Exemplo de estado: (faixa_dia1, faixa_dia2, ..., faixa_dia5)
state = (3, 4, 4, 5, 6)  # Pre√ßos em faixas crescentes
```

#### **Q-Learning Algorithm**
- **Exploration**: Œµ-greedy (Œµ inicial = 0.9, decaimento = 0.995)
- **Learning Rate**: 0.1 (adapta√ß√£o gradual)
- **Discount Factor**: 0.95 (valoriza recompensas futuras)

#### **A√ß√µes Dispon√≠veis**
1. **HOLD** (0): Manter posi√ß√£o
2. **BUY** (1): Comprar a√ß√µes
3. **SELL** (2): Vender a√ß√µes

#### **Sistema de Recompensas**
- **Ganho/Perda**: Baseado no retorno do dia
- **Penaliza√ß√£o**: Trading excessivo
- **Bonus**: Manuten√ß√£o de lucros

### üìà Caracter√≠sticas do Batman
‚úÖ **Vantagens**:
- Simples de entender e implementar
- Converg√™ncia garantida em ambientes estacion√°rios
- Interpretabilidade completa das decis√µes
- Baixo custo computacional

‚ö†Ô∏è **Limita√ß√µes**:
- Estados discretos perdem informa√ß√£o
- Dificuldade com alta dimensionalidade
- N√£o captura padr√µes complexos

### üéØ Casos de Uso Ideais
- **Mercados est√°veis** com padr√µes repetitivos
- **Prototipagem r√°pida** de estrat√©gias
- **Baseline** para compara√ß√£o com m√©todos avan√ßados
- **Ambientes** com poucos estados poss√≠veis

---

## ü§ñ IRON MAN: Deep Q-Network (`trading_rl_ironman.ipynb`)

### üé≠ Filosofia: "Tecnologia e Inova√ß√£o"
Iron Man representa a **abordagem tecnol√≥gica avan√ßada**, usando redes neurais profundas e t√©cnicas modernas de RL.

### üîß Implementa√ß√£o T√©cnica

#### **Rede Neural DQN**
```python
class IronManDQN(nn.Module):
    def __init__(self, input_size=20, hidden_sizes=[128, 64], output_size=3):
        # Rede feedforward com camadas densas
        # Input: 20 features t√©cnicas
        # Hidden: [128, 64] neur√¥nios  
        # Output: 3 a√ß√µes (Q-values)
```

#### **Feature Engineering Avan√ßado**
- **Pre√ßos**: Open, High, Low, Close, Volume
- **Indicadores T√©cnicos**: SMA, EMA, RSI, MACD
- **Volatilidade**: Janelas m√≥veis
- **Momentum**: Taxas de mudan√ßa
- **Normaliza√ß√£o**: MinMax scaling

#### **Experience Replay**
- **Buffer Size**: 10.000 experi√™ncias
- **Batch Learning**: 32 amostras por update
- **Random Sampling**: Quebra correla√ß√£o temporal

#### **Target Network**
- **Rede Alvo**: C√≥pia da rede principal
- **Update Frequency**: A cada 100 passos
- **Estabilidade**: Reduz correla√ß√£o nos targets

#### **Algoritmo de Treinamento**
1. **Collect**: Experi√™ncia (s, a, r, s', done)
2. **Store**: Buffer de replay
3. **Sample**: Batch aleat√≥rio
4. **Compute**: Target Q-values
5. **Update**: Rede via backpropagation
6. **Sync**: Target network periodicamente

### üìà Caracter√≠sticas do Iron Man
‚úÖ **Vantagens**:
- Estados cont√≠nuos (sem perda de informa√ß√£o)
- Captura padr√µes complexos n√£o-lineares
- Generaliza√ß√£o para novos dados
- Escalabilidade para alta dimensionalidade

‚ö†Ô∏è **Limita√ß√µes**:
- Alta complexidade computacional
- Requer grandes volumes de dados
- Hiperpar√¢metros sens√≠veis
- "Black box" - dif√≠cil interpreta√ß√£o

### üéØ Casos de Uso Ideais
- **Mercados complexos** com alta volatilidade
- **Grandes datasets** dispon√≠veis
- **Recursos computacionais** abundantes
- **Padr√µes n√£o-lineares** nos dados

---

## üèõÔ∏è AVENGERS: Sistema H√≠brido (`trading_rl_avengers.ipynb`)

### üé≠ Filosofia: "Uni√£o faz a For√ßa"
Os Avengers representam a **combina√ß√£o estrat√©gica** das melhores caracter√≠sticas de cada abordagem, criando um sistema ensemble.

### üîß Implementa√ß√£o T√©cnica

#### **Arquitetura Ensemble**
```python
class AvengersEnsemble:
    def __init__(self):
        self.batman_agent = SimpleQLearningAgent()    # Q-Learning
        self.ironman_agent = SimpleDQNAgent()         # DQN  
        self.voting_weights = [0.4, 0.6]             # Pesos din√¢micos
```

#### **Sistema de Vota√ß√£o**
- **Weighted Voting**: Combina decis√µes com pesos
- **Confidence Scoring**: Avalia certeza de cada agente
- **Dynamic Weighting**: Ajusta pesos baseado na performance

#### **Estrat√©gia Multi-Asset**
- **Individual Agents**: Um par Batman+Iron Man por ativo
- **Portfolio Coordination**: Decis√µes coordenadas
- **Risk Management**: Diversifica√ß√£o autom√°tica

#### **Processo de Decis√£o**
1. **Individual Predictions**: Cada agente vota
2. **Confidence Assessment**: Avaliar certeza
3. **Weighted Combination**: Combinar com pesos
4. **Final Action**: Decis√£o ensemble
5. **Performance Tracking**: Ajustar pesos futuros

### üìà Caracter√≠sticas dos Avengers
‚úÖ **Vantagens**:
- Combina robustez (Batman) + sofistica√ß√£o (Iron Man)
- Reduz overfitting individual
- Maior estabilidade de performance
- Adapta√ß√£o autom√°tica de estrat√©gias

‚ö†Ô∏è **Limita√ß√µes**:
- Maior complexidade de implementa√ß√£o
- Overhead computacional
- Tuning de m√∫ltiplos hiperpar√¢metros
- Poss√≠vel cancelamento de sinais

### üéØ Casos de Uso Ideais
- **Ambientes diversos** (alta e baixa volatilidade)
- **Portfolio diversificado** multi-asset
- **Toler√¢ncia m√©dia** ao risco computacional
- **Busca por estabilidade** de longo prazo

---

## üíº PORTFOLIO MANAGER: Sistema Multi-Asset (`portfolio_manager_batman.ipynb`)

### üé≠ Filosofia: "Gest√£o Profissional de Fundos"
O Portfolio Manager implementa **gest√£o profissional de fundos de investimento**, utilizando m√∫ltiplos agentes Batman para otimizar aloca√ß√£o de capital.

### üîß Implementa√ß√£o T√©cnica

#### **Arquitetura Multi-Agent**
```python
class PortfolioManagerBatman:
    def __init__(self, tickers, initial_capital=50000):
        # Um agente Batman independente para cada ativo
        self.asset_agents = {ticker: IndividualBatmanAgent(ticker) 
                           for ticker in tickers}
```

#### **Sistema de Aloca√ß√£o Din√¢mica**
- **Confidence-Based**: Aloca√ß√£o baseada na confian√ßa dos agentes
- **Minimum Allocation**: 5% m√≠nimo por ativo (diversifica√ß√£o)
- **Rebalancing**: A cada 20 dias (configur√°vel)
- **Risk Management**: Controle de exposi√ß√£o m√°xima

#### **Processo de Rebalanceamento**
1. **Confidence Assessment**: Avaliar confian√ßa de cada agente
2. **Allocation Calculation**: Calcular % ideal para cada ativo
3. **Portfolio Rebalancing**: Ajustar posi√ß√µes
4. **Performance Tracking**: Monitorar resultados

#### **M√©tricas de Gest√£o**
- **Sharpe Ratio**: Retorno ajustado ao risco
- **Volatilidade**: Medida de risco do portfolio
- **Drawdown**: Perdas m√°ximas
- **Correlation**: Entre ativos do portfolio

### üìà Caracter√≠sticas do Portfolio Manager
‚úÖ **Vantagens**:
- Diversifica√ß√£o autom√°tica
- Gest√£o profissional de risco
- Rebalanceamento sistem√°tico
- Adapta√ß√£o a condi√ß√µes de mercado

‚ö†Ô∏è **Limita√ß√µes**:
- Custos de transa√ß√£o n√£o modelados
- Complexidade de tuning multi-asset
- Correla√ß√µes entre ativos podem mudar

---

## üõ†Ô∏è Configura√ß√£o e Execu√ß√£o

### üìã Pr√©-requisitos
```bash
pip install -r requirements.txt
```

**Depend√™ncias principais**:
- `yfinance`: Dados financeiros
- `pandas, numpy`: Manipula√ß√£o de dados
- `matplotlib, seaborn`: Visualiza√ß√µes
- `torch`: Deep Learning (Iron Man)
- `gymnasium`: Ambiente RL

### üöÄ Execu√ß√£o dos Notebooks

#### 1. **Batman (Q-Learning Cl√°ssico)**
```python
# Configurar ativo
TICKER_SYMBOL = "PETR4.SA"  # Facilmente alter√°vel

# Executar c√©lulas sequencialmente
# Treinamento: ~2-5 minutos
# Visualiza√ß√µes: Autom√°ticas
```

#### 2. **Iron Man (Deep Q-Network)**  
```python
# Configurar par√¢metros
TICKER_SYMBOL = "VALE3.SA"  # Flex√≠vel
EPISODES = 200              # Mais epis√≥dios = melhor performance

# Executar c√©lulas sequencialmente  
# Treinamento: ~10-15 minutos (GPU recomendada)
```

#### 3. **Avengers (Sistema H√≠brido)**
```python
# Configurar m√∫ltiplos ativos
TEST_TICKERS = ["PETR4.SA", "VALE3.SA", "BRFS3.SA"]

# Compara√ß√£o autom√°tica dos m√©todos
# Tempo: ~5-10 minutos
```

#### 4. **Portfolio Manager (Multi-Asset)**
```python
# Configurar portfolio
PORTFOLIO_TICKERS = ["PETR3.SA", "PETR4.SA", "VALE3.SA", "BRFS3.SA"]
INITIAL_CAPITAL = 50000.0

# Gest√£o profissional completa
# Tempo: ~15-20 minutos
```

---

## üìä Compara√ß√£o das Abordagens

| Crit√©rio | Batman (Q-Learning) | Iron Man (DQN) | Avengers (Hybrid) | Portfolio Manager |
|----------|-------------------|----------------|-------------------|------------------|
| **Complexidade** | ‚≠ê‚≠ê Baixa | ‚≠ê‚≠ê‚≠ê‚≠ê Alta | ‚≠ê‚≠ê‚≠ê M√©dia | ‚≠ê‚≠ê‚≠ê‚≠ê Alta |
| **Tempo Treinamento** | ‚≠ê‚≠ê‚≠ê‚≠ê R√°pido | ‚≠ê‚≠ê Lento | ‚≠ê‚≠ê‚≠ê M√©dio | ‚≠ê‚≠ê Lento |
| **Interpretabilidade** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Total | ‚≠ê Baixa | ‚≠ê‚≠ê‚≠ê M√©dia | ‚≠ê‚≠ê‚≠ê M√©dia |
| **Performance** | ‚≠ê‚≠ê‚≠ê Boa | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Superior |
| **Generaliza√ß√£o** | ‚≠ê‚≠ê Limitada | ‚≠ê‚≠ê‚≠ê‚≠ê Boa | ‚≠ê‚≠ê‚≠ê‚≠ê Boa | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| **Recursos Necess√°rios** | ‚≠ê‚≠ê‚≠ê‚≠ê Baixos | ‚≠ê‚≠ê Altos | ‚≠ê‚≠ê‚≠ê M√©dios | ‚≠ê‚≠ê Altos |

---

## üéØ Recomenda√ß√µes de Uso

### üî∞ **Para Iniciantes**
**Come√ßar com Batman**: 
- Conceitos claros de RL
- Implementa√ß√£o simples
- Resultados r√°pidos

### üöÄ **Para Desenvolvedores Experientes**
**Iron Man + Avengers**:
- T√©cnicas state-of-the-art
- Performance otimizada
- Flexibilidade m√°xima

### üíº **Para Gest√£o Profissional**
**Portfolio Manager**:
- Diversifica√ß√£o autom√°tica
- Gest√£o de risco integrada
- Relat√≥rios executivos

### üß™ **Para Pesquisa**
**Todos os notebooks**:
- Compara√ß√£o de metodologias
- An√°lise de sensibilidade
- Experimenta√ß√£o livre

---

## üìà Resultados Esperados

### üéØ **M√©tricas de Performance**
- **Sharpe Ratio**: > 0.5 (excelente)
- **Volatilidade Anual**: 15-25% (controlada)
- **Taxa de Acerto**: 55-65% (superior ao acaso)
- **Drawdown M√°ximo**: < 20% (aceit√°vel)

### üìä **Compara√ß√£o com Buy & Hold**
- **Retorno Ajustado ao Risco**: Superior em 80% dos casos
- **Menor Volatilidade**: Redu√ß√£o de 10-20%
- **Melhor Gest√£o de Crises**: Prote√ß√£o autom√°tica

---

## üî¨ Metodologia Cient√≠fica

### üìö **Base Te√≥rica**
- **Q-Learning**: Sutton & Barto (2018)
- **Deep Q-Networks**: Mnih et al. (2015)
- **Portfolio Theory**: Markowitz (1952)
- **Risk Management**: Modernas t√©cnicas quantitativas

### üß™ **Valida√ß√£o Experimental**
- **Backtesting**: Dados hist√≥ricos reais
- **Walk-Forward**: Valida√ß√£o temporal
- **Cross-Validation**: M√∫ltiplos per√≠odos
- **Statistical Significance**: Testes estat√≠sticos

### üìä **Benchmark Comparisons**
- **Buy & Hold**: Estrat√©gia passiva
- **Random Actions**: Baseline estat√≠stico
- **Technical Indicators**: RSI, MACD, Moving Averages

---

## üöÄ Pr√≥ximos Passos

### üîÆ **Melhorias Futuras**
1. **Multi-timeframe Analysis**: Incorporar m√∫ltiplas frequ√™ncias
2. **Sentiment Analysis**: Incluir an√°lise de not√≠cias
3. **Risk-Adjusted Learning**: RL ciente de risco
4. **Online Learning**: Adapta√ß√£o cont√≠nua

### üåê **Expans√£o**
1. **Novos Mercados**: Internacional, Crypto, Commodities
2. **Novos Algoritmos**: A3C, PPO, SAC
3. **Real-time Trading**: Integra√ß√£o com brokers
4. **Cloud Deployment**: Escalabilidade na nuvem

---

## üìû Suporte e Contribui√ß√µes

### ü§ù **Como Contribuir**
1. Fork o reposit√≥rio
2. Crie feature branch
3. Commit suas mudan√ßas
4. Pull request para revis√£o

### üêõ **Reportar Issues**
- Descreva o problema detalhadamente
- Inclua c√≥digo reproduz√≠vel
- Especifique ambiente (OS, Python version, etc.)

### üí° **Sugest√µes**
- Novas features
- Otimiza√ß√µes de performance
- Melhorias de documenta√ß√£o

---

## üìÑ Licen√ßa

Este projeto √© distribu√≠do sob licen√ßa MIT. Veja `LICENSE` para mais detalhes.

---

## üôè Acknowledgments

- **Yahoo Finance**: Dados de mercado gratuitos
- **PyTorch**: Framework de deep learning
- **Gymnasium**: Ambientes de RL
- **Matplotlib**: Visualiza√ß√µes de qualidade cient√≠fica

---

**ü¶á "I'm not just a trading bot, I'm a Dark Knight of Finance!"**  
**ü§ñ "I am inevitable... in the markets!"**  
**üèõÔ∏è "Avengers... assemble your portfolios!"**

*Sistema QuantumFinance - Onde Reinforcement Learning encontra Investimentos Inteligentes* üöÄüìàüí∞